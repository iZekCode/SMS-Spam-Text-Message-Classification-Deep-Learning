{"cells":[{"cell_type":"markdown","id":"def8e46c-7606-4991-9b29-9223ccacd54b","metadata":{"id":"def8e46c-7606-4991-9b29-9223ccacd54b"},"source":["# SMS Spam Text Message Classification using Deep Learning"]},{"cell_type":"markdown","id":"d333f8fe-3ae6-4060-b597-e9f7d9e37582","metadata":{"id":"d333f8fe-3ae6-4060-b597-e9f7d9e37582"},"source":["## Dataset\n","\n","**Spam Text Message Classification Dataset**: A collection of labeled SMS messages, categorized as \"spam\" or \"ham\". [Dataset Link](https://www.kaggle.com/uciml/sms-spam-collection-dataset)\n"]},{"cell_type":"markdown","id":"25ecc459-5019-42d8-84a6-8644cecafef3","metadata":{"id":"25ecc459-5019-42d8-84a6-8644cecafef3"},"source":["### 1. Package and Module Installation"]},{"cell_type":"code","execution_count":null,"id":"62606ca1-5868-4c65-93ef-1d6ee8d8d59a","metadata":{"id":"62606ca1-5868-4c65-93ef-1d6ee8d8d59a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724829989057,"user_tz":-420,"elapsed":9004,"user":{"displayName":"Filbert Naldo Wijaya","userId":"13574207107755868778"}},"outputId":"947bd50d-61e5-4ca5-d40c-3f7ba38b5d9b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n","Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n","Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n","Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.7.1)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"]}],"source":["!pip install scikit-learn tensorflow"]},{"cell_type":"markdown","id":"b0837717-de95-4193-9898-e2f4cadfcfc6","metadata":{"id":"b0837717-de95-4193-9898-e2f4cadfcfc6"},"source":["### 2. Data Loading and Preprocessing"]},{"cell_type":"code","execution_count":null,"id":"3b0e5e58-277e-41ef-9b1c-951e5d150191","metadata":{"id":"3b0e5e58-277e-41ef-9b1c-951e5d150191","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724829500100,"user_tz":-420,"elapsed":2446,"user":{"displayName":"Filbert Naldo Wijaya","userId":"13574207107755868778"}},"outputId":"fd204557-2357-45cb-8e2f-3bc38a39b3c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"execute_result","data":{"text/plain":["(label      0\n"," message    0\n"," dtype: int64,\n"," label\n"," ham     4825\n"," spam     747\n"," Name: count, dtype: int64)"]},"metadata":{},"execution_count":11}],"source":["# Load data\n","import pandas as pd\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","file_path = '/content/drive/My Drive/REATBFZR_Filbert Naldo Wijaya/spam.csv'\n","data = pd.read_csv(file_path, encoding='latin-1')\n","\n","data.head()\n","\n","# Drop unnecessary columns\n","data = data.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'])\n","\n","# Rename the columns for clarity\n","data.columns = ['label', 'message']\n","\n","# Check for missing values\n","missing_values = data.isnull().sum()\n","\n","# Check the distribution of the labels\n","label_distribution = data['label'].value_counts()\n","\n","missing_values, label_distribution"]},{"cell_type":"markdown","id":"30ce0c59-0e94-480a-81ae-528e68356a15","metadata":{"id":"30ce0c59-0e94-480a-81ae-528e68356a15"},"source":["### 3. Model Building"]},{"cell_type":"code","execution_count":null,"id":"1aa3c3f7-c6c5-4419-9b25-e8d7a8ec345a","metadata":{"id":"1aa3c3f7-c6c5-4419-9b25-e8d7a8ec345a"},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","# Encode labels\n","label_encoder = LabelEncoder()\n","data['label'] = label_encoder.fit_transform(data['label'])\n","\n","# Split data\n","X_train, X_test, y_train, y_test = train_test_split(data['message'], data['label'], test_size=0.2, random_state=42)\n","\n","# Vectorize text data\n","vectorizer = TfidfVectorizer()\n","X_train_vec = vectorizer.fit_transform(X_train).toarray()\n","X_test_vec = vectorizer.transform(X_test).toarray()\n","\n","# Convert to PyTorch tensors\n","X_train_tensor = torch.tensor(X_train_vec, dtype=torch.float32)\n","X_test_tensor = torch.tensor(X_test_vec, dtype=torch.float32)\n","y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n","y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)"]},{"cell_type":"markdown","id":"585b925f-fcf0-4518-81d8-598dba65d646","metadata":{"id":"585b925f-fcf0-4518-81d8-598dba65d646"},"source":["### 4. Model Training"]},{"cell_type":"code","execution_count":null,"id":"ee33d9bc-2b35-4f78-b5d8-3eb65db1e361","metadata":{"id":"ee33d9bc-2b35-4f78-b5d8-3eb65db1e361","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724831752025,"user_tz":-420,"elapsed":28794,"user":{"displayName":"Filbert Naldo Wijaya","userId":"13574207107755868778"}},"outputId":"49b32906-8a48-46cd-889b-a31ba6efe2d1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [20/100], Loss: 0.6063\n","Epoch [40/100], Loss: 0.4712\n","Epoch [60/100], Loss: 0.2216\n","Epoch [80/100], Loss: 0.0732\n","Epoch [100/100], Loss: 0.0283\n"]}],"source":["# for Loss Value\n","dl_loss_value = 0\n","\n","# Building Model\n","class SpamClassifier(nn.Module):\n","    def __init__(self, input_dim, hidden_dim1, hidden_dim2):\n","        super(SpamClassifier, self).__init__()\n","        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n","        self.dropout = nn.Dropout(0.5)\n","        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n","        self.fc3 = nn.Linear(hidden_dim2, 1)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        x = torch.relu(self.fc1(x))\n","        x = self.dropout(x)\n","        x = torch.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        x = self.sigmoid(x)\n","        return x\n","\n","# Instantiate model, loss function, and optimizer\n","input_dim = X_train_vec.shape[1]  # Number of features\n","hidden_dim = 10\n","model = SpamClassifier(input_dim=X_train_vec.shape[1], hidden_dim1=64, hidden_dim2=32)\n","criterion = nn.BCELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Training loop\n","num_epochs = 100\n","for epoch in range(num_epochs):\n","    model.train()\n","\n","    # Forward pass\n","    outputs = model(X_train_tensor)\n","    loss = criterion(outputs, y_train_tensor)\n","\n","    # Backward pass and optimization\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if (epoch+1) % 20 == 0:\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n","        dl_loss_value = loss.item()"]},{"cell_type":"markdown","id":"1d391ec9-ca95-4c56-b4f6-fccf8e0be14a","metadata":{"id":"1d391ec9-ca95-4c56-b4f6-fccf8e0be14a"},"source":["### 5. Model Evaluation"]},{"cell_type":"code","execution_count":null,"id":"c8ca8f78-e33c-4552-9f4d-8bed711e661f","metadata":{"id":"c8ca8f78-e33c-4552-9f4d-8bed711e661f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724831758392,"user_tz":-420,"elapsed":341,"user":{"displayName":"Filbert Naldo Wijaya","userId":"13574207107755868778"}},"outputId":"6287d962-3fb0-4d29-8f7f-146f03df2eba"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy on test set: 0.9812\n"]}],"source":["# for Accuracy\n","dl_accuracy = 0\n","\n","model.eval()\n","with torch.no_grad():\n","    test_outputs = model(X_test_tensor)\n","    predicted = test_outputs.round().squeeze().numpy()\n","    accuracy = (predicted == y_test_tensor.squeeze().numpy()).mean()\n","    print(f'Accuracy on test set: {accuracy:.4f}')\n","    dl_accuracy = accuracy"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"colab":{"provenance":[{"file_id":"1HzN6jqbFPHA7IUPRtkZpk2oGTta99Uqg","timestamp":1724811566040}]}},"nbformat":4,"nbformat_minor":5}